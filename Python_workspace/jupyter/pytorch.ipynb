{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[26.1300, 26.0000, 25.8700, 23.7500, 22.6300]]])\n"
     ]
    }
   ],
   "source": [
    "import quandl\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "def get_tensor_data(data_code: str, prev_day: int, today: int):\n",
    "    tensor_x = []\n",
    "    tensor_y = []\n",
    "    get_data = quandl.get(data_code, returns=\"numpy\")\n",
    "    for k in range(prev_day):\n",
    "        tensor_x.append(get_data[today - prev_day + k][1])\n",
    "    tensor_y.append(get_data[today][1])\n",
    "    tensor_x = Variable(torch.from_numpy(np.array(tensor_x))).float().view(1, 1, prev_day)\n",
    "    tensor_y = Variable(torch.from_numpy(np.array(tensor_y))).float().view(1, 1, 1)\n",
    "    return tensor_x, tensor_y\n",
    "\n",
    "\n",
    "a, b = get_tensor_data(\"WIKI/AAPL\", 5, 60)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Value\n",
      "Date             \n",
      "1986-01-02  25.56\n",
      "1986-01-03  26.00\n",
      "1986-01-06  26.53\n",
      "1986-01-07  25.85\n",
      "1986-01-08  25.87\n",
      "...           ...\n",
      "2019-12-10  59.22\n",
      "2019-12-11  58.74\n",
      "2019-12-12  59.18\n",
      "2019-12-13  60.11\n",
      "2019-12-16  60.21\n",
      "\n",
      "[8575 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "import quandl\n",
    "mydata = quandl.get(\"EIA/PET_RWTC_D\")\n",
    "print(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n",
      "tensor([[-6.9000e-01, -2.2103e+00, -1.4920e+00, -1.2217e+00, -4.7408e-01,\n",
      "          7.7951e-01,  4.0186e-01, -1.0035e+00,  1.6760e-01, -6.2444e-01],\n",
      "        [ 2.6931e-01, -1.5185e+00,  1.6785e+00,  1.1408e+00, -2.1106e-01,\n",
      "         -8.5739e-01,  2.4638e-01, -1.3587e+00, -3.2566e-01, -2.8288e+00],\n",
      "        [-1.4382e+00,  1.4113e+00,  2.1072e+00, -5.1763e-01, -6.9465e-01,\n",
      "         -3.1045e-01, -7.7671e-02, -2.0921e+00,  5.6805e-01, -1.5776e+00],\n",
      "        [-6.4593e-02,  1.7835e+00,  2.3466e-01,  2.1966e+00,  8.9513e-01,\n",
      "          5.5222e-02,  1.4111e+00,  1.1989e-01, -2.8702e-01, -1.9519e+00],\n",
      "        [-3.9682e-01, -3.9811e-01, -8.2933e-01,  1.2130e+00,  2.5004e+00,\n",
      "         -8.8457e-02, -2.1007e+00,  2.8707e-01,  5.7051e-01, -1.5280e+00],\n",
      "        [ 1.7099e+00,  7.4233e-01, -9.2084e-01, -5.1306e-01,  1.1613e+00,\n",
      "          4.8676e-01, -1.5808e+00, -7.1179e-01, -1.4864e+00, -3.9781e-02],\n",
      "        [ 1.8891e-01, -1.3023e+00,  1.4401e+00,  2.2043e-01,  3.4276e+00,\n",
      "         -2.7247e+00,  6.8319e-01,  2.9640e-01, -1.7445e+00, -1.7383e+00],\n",
      "        [ 4.5741e-01,  9.0642e-01,  1.2138e+00,  7.2663e-01, -8.8245e-01,\n",
      "          1.7943e+00,  2.5521e+00,  2.2427e+00, -6.1741e-02,  2.7470e-01],\n",
      "        [-1.7005e+00, -1.2553e+00,  1.3974e+00,  2.0616e-01,  3.9669e-01,\n",
      "         -1.0547e+00,  1.0712e+00,  3.7633e-01,  6.5462e-01, -8.2554e-02],\n",
      "        [-5.6443e-01, -8.3610e-01,  1.2750e+00,  7.0990e-01, -8.0219e-03,\n",
      "         -1.1378e+00, -8.3612e-01, -1.0386e-01,  1.1289e+00,  1.2973e+00],\n",
      "        [ 3.5168e-01, -6.1215e-02,  1.3732e+00, -1.1204e+00, -1.0131e-01,\n",
      "         -2.1484e+00,  1.7339e-01,  4.0759e-02, -6.0234e-01,  1.0142e+00],\n",
      "        [-2.3150e-01, -1.7666e-04,  1.8220e+00,  1.1307e+00,  7.3560e-01,\n",
      "         -7.6261e-01,  5.3833e-01, -3.5016e-02, -4.9812e-01,  8.9857e-01],\n",
      "        [-2.1898e-01,  7.2418e-01,  1.5203e+00, -1.8262e-01,  1.0880e+00,\n",
      "         -4.1922e-01,  3.5247e-02, -1.1120e+00, -1.5694e+00,  1.0270e+00],\n",
      "        [ 8.8557e-02,  1.9472e-01,  8.3335e-01,  3.8390e-01, -7.5112e-01,\n",
      "         -1.3735e+00,  7.4717e-01,  1.0593e+00,  4.8790e-01, -6.2921e-01],\n",
      "        [-2.6703e-01, -6.5924e-01,  4.5362e-01, -8.2528e-02,  9.7733e-01,\n",
      "         -4.2642e-01,  4.2611e-01, -1.5756e+00,  1.1434e+00, -9.2958e-02],\n",
      "        [ 3.0467e-02, -5.9458e-01, -5.4215e-01,  1.8946e+00, -4.0452e-01,\n",
      "         -1.0097e+00,  1.2880e+00,  1.5146e-01, -8.1818e-01,  3.9022e-01],\n",
      "        [-4.1068e-02, -2.1631e-01,  2.3236e-01,  1.7723e-01,  1.8065e-01,\n",
      "         -2.9128e-01,  1.5048e+00,  1.6407e+00, -3.9141e-01,  4.6670e-01],\n",
      "        [-5.5417e-02, -4.7260e-01,  1.2191e+00,  4.2129e-01,  3.7386e-01,\n",
      "          2.2138e+00, -5.0127e-01,  4.0056e-01, -3.5625e-01, -1.8227e-01],\n",
      "        [ 3.0234e-01, -2.6297e+00, -6.5656e-01, -5.6758e-02, -6.6327e-01,\n",
      "         -1.1316e+00, -4.4076e-01, -6.8096e-01,  8.2609e-01, -9.4583e-01],\n",
      "        [ 5.0303e-01,  1.9224e-01,  2.6037e+00, -6.8855e-01, -2.1080e-03,\n",
      "          1.0946e+00,  5.4738e-01,  8.9492e-01,  2.6003e-01,  2.1892e+00],\n",
      "        [ 9.9583e-02, -2.6416e-01,  1.4747e+00,  6.4044e-01,  7.0702e-01,\n",
      "          1.0109e-01,  3.7876e-01, -8.1153e-01,  1.4522e-01,  8.3172e-01],\n",
      "        [-6.5013e-01, -5.6187e-01,  5.3038e-02,  1.7538e+00, -7.0403e-01,\n",
      "         -2.7386e+00, -6.5881e-01, -2.1614e+00, -5.4407e-01,  1.7372e-01],\n",
      "        [-1.4527e-01, -2.1963e-01, -1.1955e+00, -1.2411e+00,  1.6112e+00,\n",
      "         -8.2288e-01,  9.5030e-01, -1.2345e+00, -1.2318e-01,  2.1407e-01],\n",
      "        [-5.7892e-01,  3.0310e-01, -2.4945e-01,  4.9152e-01, -4.9337e-01,\n",
      "         -4.9485e-01,  1.9113e-01, -1.8189e-01,  3.3286e-01, -2.3911e-01],\n",
      "        [-1.7628e+00,  1.4215e+00, -3.3271e-01, -3.1404e-01,  2.0799e+00,\n",
      "         -1.8188e-01, -2.7926e-01,  4.3005e-01,  3.6771e-01,  2.2275e+00],\n",
      "        [-1.5104e+00, -9.2596e-01,  8.5024e-01,  4.9351e-01, -5.9758e-02,\n",
      "          1.2121e-01, -2.9545e-01,  2.7021e-01,  6.9410e-01,  1.6162e-01],\n",
      "        [-1.6618e+00, -7.7418e-01, -9.4607e-01, -9.4172e-01,  5.0684e-01,\n",
      "         -1.0534e+00, -1.6867e-02, -8.8969e-01, -1.5143e+00, -5.4136e-01],\n",
      "        [-3.6160e-01,  6.6935e-02, -1.0099e+00, -5.3826e-01, -2.1437e-01,\n",
      "          6.6318e-01, -2.8458e-01, -9.7443e-01,  1.7027e+00, -1.0659e+00],\n",
      "        [-1.2501e+00, -3.8826e-02, -6.0700e-02,  7.6485e-01, -7.9307e-01,\n",
      "         -5.7232e-01, -1.0113e+00,  1.1081e+00,  6.9788e-01, -1.4312e-01],\n",
      "        [ 1.0268e+00, -4.5451e-01, -2.2570e+00,  3.2950e-01,  2.6607e+00,\n",
      "          2.6660e+00,  1.2324e-01,  5.6614e-01, -1.9858e+00,  3.7982e-02],\n",
      "        [-2.2267e+00, -4.0285e-01,  6.3887e-01, -5.3912e-01,  1.0292e+00,\n",
      "          1.9291e+00,  6.5033e-01, -7.7057e-01, -2.0564e+00,  1.1168e+00],\n",
      "        [ 1.9772e+00,  1.2245e+00,  1.9507e+00, -1.5406e+00, -1.3639e+00,\n",
      "         -1.1382e+00,  1.1074e+00, -1.2629e+00,  1.2627e+00, -6.9148e-01],\n",
      "        [ 3.1269e-01,  2.6728e+00, -5.9121e-01,  9.4600e-02,  1.3965e-01,\n",
      "         -5.6041e-01, -4.6209e-01,  9.8219e-01,  1.7229e+00, -8.4294e-01],\n",
      "        [-5.1988e-01, -2.7153e-01, -2.1157e+00,  3.7906e-01,  6.4709e-01,\n",
      "         -2.3179e+00, -1.4306e+00,  4.6055e-01, -9.2623e-01,  1.6221e+00],\n",
      "        [ 6.7079e-01,  1.1321e-01,  4.5747e-01, -8.7687e-01,  9.4461e-01,\n",
      "         -7.3095e-01, -4.4387e-01,  1.1978e+00, -9.1240e-01,  4.9494e-01],\n",
      "        [-6.5497e-02,  1.7823e+00,  6.9256e-02,  1.2944e+00, -1.8393e+00,\n",
      "          1.1482e+00, -5.7068e-01,  1.4424e-01, -1.1431e+00, -1.0502e+00],\n",
      "        [-1.2627e+00,  1.4890e+00, -5.0755e-01,  9.7564e-01, -2.9934e-01,\n",
      "          1.5331e+00, -1.0850e+00, -4.1609e-01, -2.3648e-01,  9.7536e-02],\n",
      "        [-4.1537e-01,  7.6141e-01, -1.3257e-01, -6.7730e-01, -9.2374e-02,\n",
      "          1.5691e+00,  1.3492e-01, -1.0634e+00, -2.1157e+00, -1.0148e+00],\n",
      "        [-1.4029e+00, -1.1491e+00,  5.1361e-01,  9.1163e-01, -9.9939e-01,\n",
      "         -1.2007e+00,  1.6918e+00,  6.0801e-01, -3.0691e-01, -5.8195e-02],\n",
      "        [-8.3769e-01,  1.5386e+00, -6.5280e-01,  2.0020e+00,  6.1555e-01,\n",
      "         -6.1881e-01, -9.1832e-01, -4.6614e-01, -1.5548e+00,  2.5111e+00],\n",
      "        [ 5.6847e-01,  2.4814e-01, -4.7883e-01,  7.2023e-01,  9.8111e-01,\n",
      "         -1.2742e+00, -7.2501e-01, -4.6285e-01,  1.7102e+00, -3.4525e-01],\n",
      "        [ 4.8488e-01, -1.4515e+00,  1.1113e+00,  2.5618e+00, -1.7788e-01,\n",
      "          8.8310e-01,  1.3546e-02,  9.8241e-01,  6.0723e-01,  6.5443e-01],\n",
      "        [ 9.1524e-01, -8.7837e-01,  5.1746e-01, -8.0785e-01,  2.3634e-01,\n",
      "          2.2118e+00, -2.1918e-01, -3.1528e-01, -6.3602e-01, -4.7103e-01],\n",
      "        [-3.8970e-01,  1.0126e-01,  9.2112e-01, -1.1859e+00,  1.6107e+00,\n",
      "         -8.4987e-01, -1.8056e-01, -1.4765e+00, -9.5262e-01, -1.2689e+00],\n",
      "        [-4.0600e-01,  1.4870e+00, -2.5500e-01, -3.3087e-01,  5.5069e-01,\n",
      "          1.0843e+00,  2.2975e-02, -5.5185e-01,  7.0724e-03, -1.6912e+00],\n",
      "        [ 1.0472e+00, -6.8055e-01,  5.4954e-01, -7.4624e-01,  2.7991e+00,\n",
      "          6.8660e-01, -1.0636e+00,  7.2023e-02,  1.7461e+00,  1.7115e-01],\n",
      "        [-1.7077e+00,  1.4228e+00, -9.3823e-01,  2.0372e+00, -2.2383e-01,\n",
      "         -1.4392e+00, -6.3839e-01, -1.1717e+00, -9.2952e-01, -7.9831e-01],\n",
      "        [-2.6286e-01,  7.5675e-01,  8.2636e-01,  5.5953e-02, -5.9334e-04,\n",
      "         -5.6926e-01, -7.1441e-01, -1.4064e+00, -1.3194e+00, -1.6998e+00],\n",
      "        [-8.8043e-01,  7.2889e-01,  7.9843e-01, -1.0394e+00,  1.1308e+00,\n",
      "         -8.2705e-02,  5.5176e-01, -9.3369e-01, -7.1295e-01,  4.7636e-01],\n",
      "        [-1.5213e-02,  5.2892e-01, -1.1616e+00,  4.4090e-01,  1.2432e+00,\n",
      "         -1.3738e+00, -5.8629e-02,  1.4868e-02, -1.7386e+00, -1.1838e-02],\n",
      "        [-7.3316e-01, -1.4239e+00,  7.9598e-01,  5.6256e-01,  5.6164e-01,\n",
      "         -8.1588e-01,  1.7153e+00, -1.7322e-01,  1.9565e-01, -3.6211e-01],\n",
      "        [ 6.1264e-01,  1.3308e+00,  1.2805e-01,  1.2385e-01,  9.4036e-01,\n",
      "          9.1561e-01, -6.0986e-01, -8.0666e-01,  5.8291e-02, -6.3981e-01],\n",
      "        [-1.8038e-01, -3.2954e-01,  2.8404e-01, -1.0378e+00, -2.9834e-01,\n",
      "         -6.4481e-01, -9.6936e-01,  2.0017e+00,  4.6959e-01, -3.9695e-01],\n",
      "        [ 4.1145e-01, -1.3182e+00,  1.8058e+00, -1.7747e-01, -1.5406e+00,\n",
      "          2.2469e-01, -2.9442e-01, -3.7130e-01,  1.4239e+00,  5.2510e-01],\n",
      "        [ 6.4233e-01, -4.7497e-01,  1.7379e+00, -1.1372e-01, -4.8313e-01,\n",
      "          1.4766e+00, -4.0940e-01,  6.4531e-01,  2.1365e-01,  5.5856e-01],\n",
      "        [ 8.4852e-01,  1.4058e-01,  1.0707e+00,  1.3625e+00,  1.0511e+00,\n",
      "          2.7154e-01,  4.4572e-01, -1.9848e-01,  7.1962e-01,  5.6641e-01],\n",
      "        [ 1.8562e+00, -1.1031e+00,  5.2386e-01, -3.4894e-02,  1.8189e-01,\n",
      "          1.9886e+00, -2.1406e+00,  4.4127e-01, -2.3254e-01, -7.9207e-01],\n",
      "        [-4.9329e-02,  1.3155e+00,  1.0705e-01, -2.3351e+00,  1.1106e+00,\n",
      "          2.1944e-01, -8.5129e-01, -1.2674e+00,  2.3312e+00, -8.3211e-01],\n",
      "        [ 4.7193e-01,  1.1820e+00,  1.5880e+00, -3.0094e-01, -7.2043e-01,\n",
      "          9.3756e-01,  1.3585e+00, -4.2188e-01,  3.4025e-01,  2.0021e-01],\n",
      "        [-2.0122e-01,  3.1762e-01, -1.2244e+00, -9.4124e-01,  1.5282e+00,\n",
      "         -1.4419e+00,  1.1976e+00, -7.0592e-01,  2.9908e-01, -8.9447e-01],\n",
      "        [-9.3683e-01, -1.3720e+00,  7.6963e-01,  8.2193e-01, -1.5448e+00,\n",
      "          2.1953e+00, -4.3911e-01, -7.0657e-01,  2.6157e-01,  1.0722e+00],\n",
      "        [-9.0255e-01,  1.7080e+00, -3.3005e-01,  1.3011e+00,  1.0720e+00,\n",
      "          1.4028e+00, -1.2497e+00,  5.9320e-01,  9.8398e-01,  8.8437e-01],\n",
      "        [-1.6872e+00,  1.3801e+00, -1.7348e+00, -1.3067e-01,  5.3608e-01,\n",
      "          4.8520e-01, -4.7514e-01, -7.6102e-01, -6.9884e-01, -5.7786e-01],\n",
      "        [-1.5967e+00,  1.2876e+00, -3.2125e-02,  1.3299e+00, -5.5761e-01,\n",
      "         -1.8461e-01,  8.2539e-01,  1.2866e+00, -1.0586e+00, -6.0298e-01],\n",
      "        [ 1.0613e+00, -1.4061e+00,  1.2064e+00, -1.2112e+00,  1.8069e-02,\n",
      "         -2.1716e-01,  1.3171e+00,  2.4946e+00,  1.4565e+00, -1.1996e+00],\n",
      "        [ 1.2189e+00,  6.5235e-01,  6.5701e-01, -6.6968e-01, -8.0608e-01,\n",
      "          5.9256e-01, -1.7753e+00, -2.7744e+00, -1.8144e+00,  4.4614e-01],\n",
      "        [ 1.4231e+00, -1.4862e+00,  1.0540e+00,  1.0529e+00,  1.6178e+00,\n",
      "         -1.7645e+00, -6.9036e-01, -5.1632e-01,  8.7743e-01,  1.6518e+00],\n",
      "        [ 1.6361e+00, -9.6304e-01, -1.4961e+00, -2.3882e-01,  1.3864e+00,\n",
      "          1.0244e-01,  1.0642e+00, -1.7310e+00,  9.9716e-01, -3.2398e-01],\n",
      "        [-6.0575e-01,  4.8408e-01,  1.2936e+00,  9.9582e-01, -5.5127e-01,\n",
      "          4.1968e-01,  1.0350e-01, -5.0649e-01,  1.3328e-01,  1.3405e-01],\n",
      "        [-8.4535e-02,  6.2953e-01, -9.4491e-02,  1.4013e+00,  1.1656e+00,\n",
      "         -1.3962e+00,  1.5944e-01,  6.4441e-01, -1.5906e-01, -4.7913e-01],\n",
      "        [ 9.1927e-01, -6.9085e-01,  1.7588e+00,  8.3805e-01, -3.9493e-01,\n",
      "         -1.9138e+00,  4.8606e-01,  1.1674e-01, -1.3491e+00, -1.2786e-01],\n",
      "        [ 7.8974e-01, -2.1730e+00,  5.2522e-01,  4.4179e-01,  1.9759e-01,\n",
      "         -9.5307e-01,  4.3421e-01,  7.7220e-01,  1.2582e+00, -1.7539e+00],\n",
      "        [-2.6172e-01, -1.5780e+00, -1.5497e+00,  1.3063e-01,  5.5151e-01,\n",
      "          1.2574e+00, -5.9030e-01, -1.1591e+00, -1.6496e+00,  9.3951e-01],\n",
      "        [ 3.6287e-01, -6.0751e-01,  1.4498e+00,  6.6096e-01,  1.8336e-01,\n",
      "          2.2029e-01, -7.6245e-01,  2.5746e-01, -5.6278e-01, -9.0448e-01],\n",
      "        [-5.6630e-01, -4.5483e-01, -2.1183e+00, -3.0669e-01, -1.5056e-02,\n",
      "          2.4323e-01,  3.3276e-01,  1.5749e+00,  2.7958e-01,  4.2462e-01],\n",
      "        [-9.2865e-02, -5.1233e-01,  4.7499e-03, -4.3578e-01, -8.0158e-01,\n",
      "         -1.6179e+00,  9.8703e-02, -1.0075e+00, -6.6767e-01,  1.1350e+00],\n",
      "        [-1.3401e+00, -7.8061e-01, -1.2245e+00, -2.6622e-01, -3.0924e-01,\n",
      "         -3.0035e-01,  6.7240e-01, -1.9248e-01,  1.6806e-01,  2.3188e-01],\n",
      "        [ 1.0797e-01,  3.3631e-01, -1.7801e-02,  7.8584e-01,  1.0842e+00,\n",
      "         -2.7801e+00, -1.8377e+00,  3.3602e-01, -1.5880e+00, -3.5873e-01],\n",
      "        [ 4.3137e-01, -2.9597e-01, -1.0197e+00, -6.4480e-01, -3.4348e-01,\n",
      "          4.2622e-02, -1.6295e+00, -8.6726e-01,  1.5508e+00, -4.9049e-01],\n",
      "        [ 5.1601e-01,  1.0962e+00,  4.8231e-02,  3.7972e-01, -5.2848e-01,\n",
      "          4.5814e-01,  9.1809e-01,  8.3600e-02,  1.1274e+00, -9.2579e-02],\n",
      "        [-5.8774e-01,  1.1720e+00,  1.5512e-01, -3.4688e-01, -5.7402e-02,\n",
      "         -7.6588e-01, -1.3687e+00,  1.3022e-01, -1.2735e+00,  5.7651e-01],\n",
      "        [-6.6333e-01,  7.9235e-01, -3.1141e-01,  9.0634e-01, -2.2270e-01,\n",
      "          1.3042e-02,  4.7716e-01,  3.6364e-01,  5.1618e-01, -1.0657e+00],\n",
      "        [-1.0847e+00, -2.8951e+00,  4.4279e-01,  4.9526e-01,  1.2186e-01,\n",
      "          7.2787e-02, -5.0774e-01, -6.8135e-01,  1.0400e-01,  1.3066e+00],\n",
      "        [-1.3895e+00, -2.5436e-01,  2.5994e-01, -5.9143e-03, -2.7225e-01,\n",
      "         -6.9207e-01, -1.7918e+00, -1.3365e-01,  9.2145e-01,  7.4749e-01],\n",
      "        [ 5.9848e-01, -2.0178e+00,  3.1669e-01,  8.2822e-01,  3.0886e+00,\n",
      "         -8.3901e-01, -2.0400e-01,  1.5382e+00, -9.4217e-01, -1.0393e-01],\n",
      "        [-2.8683e-01, -1.2081e+00, -1.3653e+00,  5.1763e-01, -4.6921e-01,\n",
      "         -7.9659e-01,  2.2796e+00,  5.4608e-01, -9.6694e-03, -7.6836e-01],\n",
      "        [-1.0092e+00,  8.6178e-01, -1.4894e+00,  1.7313e+00,  3.7593e-01,\n",
      "          4.8486e-01, -1.1492e+00,  6.0428e-01,  2.9573e-01, -1.5045e+00],\n",
      "        [ 8.0899e-01, -1.0017e+00, -1.3549e+00,  9.4626e-01, -1.2706e+00,\n",
      "          6.9229e-01,  1.2631e+00,  5.4311e-01, -7.9463e-03,  3.0206e-01],\n",
      "        [-1.6779e+00,  2.5660e-01,  5.1214e-01,  1.6534e+00, -5.2179e-01,\n",
      "          8.3872e-02,  8.3005e-01,  1.8949e+00,  3.7306e-01,  1.5172e+00],\n",
      "        [ 9.3749e-01, -1.5624e+00,  5.4959e-01,  1.0794e+00,  5.2408e-01,\n",
      "          1.0738e+00,  1.0670e+00,  3.9856e-01,  1.5107e+00,  3.7957e-01],\n",
      "        [ 9.4369e-01, -1.5037e+00, -1.4528e+00, -8.0079e-01, -5.9312e-01,\n",
      "          2.7265e-01, -7.0557e-01, -1.0892e+00, -6.0627e-01,  7.0606e-01],\n",
      "        [-8.1935e-01, -5.4881e-01,  9.0587e-01,  3.3915e-01, -1.1513e+00,\n",
      "          2.0478e-01, -2.0864e-01,  5.7693e-01, -1.2791e+00, -2.5938e-01],\n",
      "        [ 6.6594e-01, -5.1665e-01,  1.8592e-02, -1.1221e-01,  1.6562e+00,\n",
      "          1.1261e+00, -5.3902e-01,  1.7699e+00, -5.5833e-01, -7.9180e-01],\n",
      "        [ 3.2060e-01,  1.7473e+00,  1.8473e+00, -1.2552e+00, -1.5926e+00,\n",
      "         -1.8757e+00,  4.2065e-01,  7.3657e-01, -1.4414e+00, -1.1032e+00],\n",
      "        [-7.8907e-01, -3.8646e-01,  1.0736e+00,  4.4956e-03,  1.5251e+00,\n",
      "          8.8770e-01, -1.4913e+00,  1.1025e+00, -4.4761e-01, -2.3876e-01],\n",
      "        [ 1.5485e-01, -1.5738e+00, -4.5254e-01, -9.9178e-01,  1.1250e+00,\n",
      "          2.6650e-01,  6.5133e-01,  4.6366e-01,  1.6237e+00, -2.5567e-01],\n",
      "        [ 1.2992e+00, -3.0631e-01, -1.8759e+00,  9.9801e-01, -1.3531e+00,\n",
      "          1.7721e-01,  5.4621e-01,  1.9424e-02,  1.0058e+00, -6.5452e-03],\n",
      "        [-6.0448e-01, -2.8376e-01, -3.1534e-01, -9.9394e-01, -1.4195e+00,\n",
      "         -1.7592e+00,  9.9725e-02,  1.8600e+00, -4.1844e-01, -1.9000e-01],\n",
      "        [-1.5394e-01, -1.3245e+00, -1.4538e+00, -1.5321e+00,  8.5300e-02,\n",
      "          1.4037e+00,  1.8562e-01, -6.6044e-01, -2.1832e+00,  8.8726e-01],\n",
      "        [ 1.6802e+00, -1.0785e+00,  6.5022e-01,  1.3032e+00, -6.1534e-01,\n",
      "          3.7832e-01,  1.1955e-01, -9.1778e-01,  1.0347e+00,  6.4449e-01]])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "# テンソルを初期化する方法\n",
    "\n",
    "# python配列から初期化\n",
    "t = torch.Tensor([[1, 2], [3, 4]])\n",
    "print(t)\n",
    "\n",
    "# numpy配列から初期化\n",
    "x = np.array([[1, 2], [3, 4]])\n",
    "t = torch.DoubleTensor(x)\n",
    "print(t)\n",
    "\n",
    "# 連番の初期化\n",
    "t = torch.arange(0, 10)\n",
    "print(t)\n",
    "\n",
    "# zeroパディングの初期化\n",
    "t = torch.zeros(100, 10)\n",
    "print(t)\n",
    "\n",
    "# 形を指定してランダム初期化\n",
    "t = torch.randn(100, 10)\n",
    "print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.Tensor(2, 2)\n",
    "print(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "data = [2., 2.3, 4.1, 2.4, 5.3, 3.2, 4.6]\n",
    "plt.plot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E:\\\\JupyterNotebook_workspace',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\python37.zip',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\DLLs',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3',\n",
      " '',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
      " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
      " 'C:\\\\Users\\\\sigur\\\\.ipython']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pprint\n",
    "pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\numpy\\\\__init__.py'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy\n",
    "numpy.__file__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E:\\\\JupyterNotebook_workspace',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\python37.zip',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3',\n",
       " '',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\Users\\\\sigur\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\sigur\\\\.ipython']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** start ***\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "初期状態\n",
      "誤差18.0\n",
      "slope: 1.000000, y-intercept: 0.000000\n",
      "\n",
      "Step: 20\n",
      "誤差3.1303158\n",
      "slope: 0.032173, y-intercept: 2.245966\n",
      "\n",
      "Step: 40\n",
      "誤差0.75231713\n",
      "slope: -0.239140, y-intercept: 3.394981\n",
      "\n",
      "Step: 60\n",
      "誤差0.18080671\n",
      "slope: -0.372117, y-intercept: 3.958278\n",
      "\n",
      "Step: 80\n",
      "誤差0.043453783\n",
      "slope: -0.437307, y-intercept: 4.234427\n",
      "\n",
      "Step: 100\n",
      "誤差0.010443389\n",
      "slope: -0.469265, y-intercept: 4.369806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "*** end ***\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "\n",
    "sys.stderr.write(\"*** start ***\\n\")\n",
    "\n",
    "input_x = [[1.],[5.]]\n",
    "input_y = [[4.],[2.]]\n",
    "\n",
    "x = tf.compat.v1.placeholder(\"float\", [None, 1])\n",
    "y_ = tf.compat.v1.placeholder(\"float\", [None, 1])\n",
    "\n",
    "a = tf.Variable([1.], name=\"slope\")\n",
    "b = tf.Variable([0.], name=\"y-intercept\")\n",
    "y = tf.multiply(a, x) + b\n",
    "\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "\n",
    "# 誤差関数\n",
    "loss = tf.reduce_sum(tf.square(y_ - y))\n",
    "\n",
    "# トレーニング方法は、勾配降下法を選択\n",
    "train_step = tf.compat.v1.train.GradientDescentOptimizer(0.03).minimize(loss)\n",
    "\n",
    "\n",
    "with tf.compat.v1.Session() as sess:\n",
    "    sess.run(init)\n",
    "    print('初期状態')\n",
    "    print('誤差' + str(sess.run(loss, feed_dict={x: input_x, y_: input_y})))\n",
    "    print(\"slope: %f, y-intercept: %f\" % (sess.run(a), sess.run(b)))\n",
    "\n",
    "    for step in range(100):\n",
    "        sess.run(train_step, feed_dict={x: input_x, y_: input_y})\n",
    "        if (step+1) % 20 == 0:\n",
    "            print('\\nStep: %s' % (step+1))\n",
    "            print('誤差' + str(sess.run(loss, feed_dict={x: input_x, y_: input_y})))\n",
    "            print(\"slope: %f, y-intercept: %f\" % (sess.run(a), sess.run(b)))\n",
    "#\n",
    "sys.stderr.write(\"*** end ***\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "   32/60000 [..............................] - ETA: 58:35"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": " Blas GEMM launch failed : a.shape=(32, 784), b.shape=(784, 512), m=32, n=512, k=784\n\t [[node sequential/dense/MatMul (defined at C:\\Users\\sigur\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_706]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2034fbee0795>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m               metrics=['accuracy'])\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    518\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 520\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    521\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    522\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mInternalError\u001b[0m:  Blas GEMM launch failed : a.shape=(32, 784), b.shape=(784, 512), m=32, n=512, k=784\n\t [[node sequential/dense/MatMul (defined at C:\\Users\\sigur\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\framework\\ops.py:1751) ]] [Op:__inference_distributed_function_706]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
